# from telegram import Update
# from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
# import pathlib
# import textwrap
# import google.generativeai as genai
# import uvicorn
# import os





# genai.configure(api_key='AIzaSyCBkKSe9dtzeQCVW5Of07_QyngJAGONtlQ')

# model = genai.GenerativeModel('models/gemini-1.5-pro-latest')

# import docx2txt

# file_path = pathlib.Path('WA_chatbot.docx')
# content = docx2txt.process(file_path)


# TOKEN = '6766016859:AAH5CQ3MA5n9pPRUXlpcsWmBVtVg52e5ejo'
# BOT_USERNAME = '@algooruBot'

# # Define command handlers
# async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("Hi there!ğŸ‘‹I'm ready to answer your questions. Ask me anything!")

# async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("I am a Test bot. Please type something so I can respond!")

# async def custom_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("This is a custom command!")

# # Define message handler
# def handle_response(prompt:str) ->str:
#     processed: str = prompt.lower()
#     if prompt.lower() in ("hi", "hello", "hey"):  # Handle multiple greetings
#         response = "How can I help you today?ğŸ˜Š"
#     elif prompt.lower() in ("what is algooru","what services do you offer?","can you give me an overview of your platform","who do you serve?","what does your platform provide?","what are your services?"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("where is alguru located","where is your headquarters?","where is your location?","where is your company?","where do you conduct sessions?","what are your services?"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("how can i work with you?","how can i work with you"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("is there a limit to the number of packages i'm allowed to have?","is there a limit to the number of packages i'm allowed to have"):
#         response = "You can subscribe to multiple packages simultaneously, and our team will assist you with your request."
#     elif prompt.lower() in ("how much do you charge for a session?","how much do you charge for a session"):
#         response = "Our prices per hour range from 88 to 152 SAR, depending on your chosen package. Our experts will recommend a package that best fits your needs and preferences."

#     else:
#         flag = model.generate_content(["If "+prompt+" is related to anything like LGBTQ+, mention of homosexuality, politics, war news, crimes, etc. return '1' else return '0'"])
#         # st.write(flag.text)
#         if '1' in str(flag.text):
#             response = "I am a parenting and educational assistance bot. I am unable to answer these questions. Please ask questions related to educational assistance."
#         elif '0' in str(flag.text):            
#         # context_truncated = textwrap.shorten(content, width=1000)
#             response1 = model.generate_content([
#                 "You are an expert customer assistant from AlGooru Team. I'll give you question and context and you'll return the answer.Answer in 60 words in a paragraph. Do not give random answers. ",
#                 f"Question: {prompt}",
#                 f"Context: {content}"
#             ])
#             response = f"{response1.text}"
#         else:
#             response = "I'm sorry, can you please try rephrasing your question?"
#     return response


# async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     message_type: str = update.message.chat.type
#     text: str = update.message.text
#     # Your message handling logic goes here
#     print(f'User ({update.message.chat.id}) in {message_type}: "{text}"')

#     # if message_type=='group':
#     #     if BOT_USERNAME in text:
#     #         new_text: str = text.replace(BOT_USERNAME,'').strip()
#     #         response: str = handle_response(new_text)
#     #     else:
#     #         return
#     # else:
#     response:str=handle_response(text)
#     print('BOT:',response)
#     await update.message.reply_text(response)

    

# # Define error handler
# async def error(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     print(f"Update {update} caused error {context.error}")

# if __name__ == '__main__':
#     print('Starting bot ...')
#     app = Application.builder().token(TOKEN).build()
#     HOST = os.getenv("HOST","0.0.0.0")
#     PORT = os.getenv("PORT",8080)
#     uvicorn.run(app,host=HOST,port = PORT)
    
#     # Register command handlers
#     app.add_handler(CommandHandler('start', start_command))
#     app.add_handler(CommandHandler('help', help_command))
#     app.add_handler(CommandHandler('custom', custom_command))

#     # Register message handler
#     app.add_handler(MessageHandler(filters.TEXT, handle_message))

#     # Register error handler
#     app.add_error_handler(error)

#     # Start polling
#     print("Polling...")
#     app.run_polling(poll_interval=3)


# from telegram import Update
# from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
# import pathlib
# import textwrap
# import google.generativeai as genai
# import os
# import uvicorn
# import asyncio
# import time

# genai.configure(api_key='AIzaSyDR5LnttOKA1QZWckv8gxrm8FRwOtkj9isAIzaSyDR5LnttOKA1QZWckv8gxrm8FRwOtkj9is')
# model = genai.GenerativeModel('gemini-1.5-flash-latest')

# import docx2txt

# file_path = pathlib.Path('WA_chatbot.docx')
# content = docx2txt.process(file_path)


# TOKEN = '6766016859:AAH5CQ3MA5n9pPRUXlpcsWmBVtVg52e5ejo'
# BOT_USERNAME = '@algooruBot'

# # Cache and cache expiry time in seconds (e.g., 3600 seconds = 1 hour)
# cache = {}
# cache_expiry = 3600

# # Function to clear cache
# async def clear_cache():
#     while True:
#         await asyncio.sleep(cache_expiry)
#         cache.clear()
#         print("Cache cleared")

# # Define command handlers
# async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("Hi there!ğŸ‘‹I'm ready to answer your questions. Ask me anything!")

# async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("I am a Test bot. Please type something so I can respond!")

# async def custom_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("This is a custom command!")

# # Define message handler
# def handle_response(prompt: str) -> str:
#     # Check cache first
#     if prompt in cache:
#         return cache[prompt]
    
#     processed: str = prompt.lower()
#     if prompt.lower() in ("hi", "hello", "hey"):  # Handle multiple greetings
#         response = "How can I help you today?ğŸ˜Š"
#     elif prompt.lower() in ("what is algooru","what services do you offer?","can you give me an overview of your platform","who do you serve?","what does your platform provide?","what are your services?"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("where is alguru located","where is your headquarters?","where is your location?","where is your company?","where do you conduct sessions?","what are your services?"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("how can i work with you?","how can i work with you"):
#         response = "AlGooru is an educational platform that connects parents and students with qualified and vetted tutors, offering in-person and online sessions in 20 core subjects that cover all educational levels, along with some university and professional fields."
#     elif prompt.lower() in ("is there a limit to the number of packages i'm allowed to have?","is there a limit to the number of packages i'm allowed to have"):
#         response = "You can subscribe to multiple packages simultaneously, and our team will assist you with your request."
#     elif prompt.lower() in ("how much do you charge for a session?","how much do you charge for a session"):
#         response = "Our prices per hour range from 88 to 152 SAR, depending on your chosen package. Our experts will recommend a package that best fits your needs and preferences."

#     else:
#         flag = model.generate_content(["If "+prompt+" is related to anything like LGBTQ+, mention of homosexuality, politics, war news, crimes, etc. return '1' else return '0'"])
#         # st.write(flag.text)
#         if '1' in str(flag.text):
#             response = "I am a parenting and educational assistance bot. I am unable to answer these questions. Please ask questions related to educational assistance."
#         elif '0' in str(flag.text):            
#         # context_truncated = textwrap.shorten(content, width=1000)
#             response1 = model.generate_content([
#                 "You are an expert customer assistant from AlGooru Team. I'll give you question and context and you'll return the answer.Answer in 60 words in a paragraph. Do not give random answers. ",
#                 f"Question: {prompt}",
#                 f"Context: {content}"
#             ])
#             response = f"{response1.text}"
#         else:
#             response = "I'm sorry, can you please try rephrasing your question?"

#     # Cache the response
#     cache[prompt] = response

#     return response


# async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     message_type: str = update.message.chat.type
#     text: str = update.message.text
#     # Your message handling logic goes here
#     print(f'User ({update.message.chat.id}) in {message_type}: "{text}"')

#     # if message_type=='group':
#     #     if BOT_USERNAME in text:
#     #         new_text: str = text.replace(BOT_USERNAME,'').strip()
#     #         response: str = handle_response(new_text)
#     #     else:
#     #         return
#     # else:
#     response:str=handle_response(text)
#     print('BOT:',response)
#     await update.message.reply_text(response)

    

# # Define error handler
# async def error(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     print(f"Update {update} caused error {context.error}")

# if __name__ == '__main__':
#     print('Starting bot ...')
#     app = Application.builder().token(TOKEN).build()
#     # HOST = os.getenv("HOST","0.0.0.0")
#     # PORT = os.getenv("PORT",8080)
#     # uvicorn.run(app,host=HOST,port = PORT)

#     # Register command handlers
#     app.add_handler(CommandHandler('start', start_command))
#     app.add_handler(CommandHandler('help', help_command))
#     app.add_handler(CommandHandler('custom', custom_command))

#     # Register message handler
#     app.add_handler(MessageHandler(filters.TEXT, handle_message))

#     # Register error handler
#     app.add_error_handler(error)

#     # Start cache clearing loop
#     app.job_queue.run_repeating(lambda _: asyncio.create_task(clear_cache()), interval=cache_expiry)

#     # Start polling
#     print("Polling...")
#     app.run_polling()


import streamlit as st
import pathlib
import textwrap
import google.generativeai as genai

genai.configure(api_key='AIzaSyCBkKSe9dtzeQCVW5Of07_QyngJAGONtlQ')

model = genai.GenerativeModel('models/gemini-1.5-pro-latest')
safe = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_LOW_AND_ABOVE",
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_LOW_AND_ABOVE",
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_LOW_AND_ABOVE",
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_LOW_AND_ABOVE",
    },
]

import docx2txt

file_path = pathlib.Path('WA_chatbot_arabic.docx')
content = docx2txt.process(file_path)

if "messages" not in st.session_state:
    st.session_state.messages = []

with st.chat_message("system"):
    st.write("""
Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡ğŸ‘‹ Ù…Ø¹Ùƒ Ø¨ÙˆØª Ø§Ù„Ù‚ÙˆØ±ÙˆØŒ ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø§Ø®Ø¯Ù…Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ
""")
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Ø£Ø¯Ø®Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."):
    with st.chat_message("user"):
        st.markdown(prompt)


    # Ù…Ø§ Ù‡Ùˆ "Ø§Ù„Ø¬ÙˆÙ‘Ø±Ùˆ"ØŸ
    st.session_state.messages.append({"role": "user", "content": prompt})

    if prompt.lower() in ("Ù…Ø±Ø­Ø¨Ø§ ", "Ù…Ø±Ø­Ø¨Ø§ ", "Ù‡Ø§ÙŠ "):  # Handle multiple greetings
        response = "ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
    elif prompt.lower() in ("Ù…Ø§ Ù‡Ùˆ Ø§Ù„ØºÙˆØ±Ùˆ","Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªÙ‚Ø¯Ù…Ù‡Ø§ØŸ","Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ¹Ø·ÙŠÙ†ÙŠ Ù„Ù…Ø­Ø© Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ","Ù…Ù† ØªØ®Ø¯Ù…ØŸ","Ù…Ø§Ø°Ø§ ØªÙˆÙØ± Ù…Ù†ØµØªÙƒØŸ","Ù…Ø§ Ù‡ÙŠ Ø®Ø¯Ù…Ø§ØªÙƒØŸ"):
        response = "AlGooru Ù‡ÙŠ Ù…Ù†ØµØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØ±Ø¨Ø· Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù…Ø¹Ù„Ù…ÙŠÙ† Ù…Ø¤Ù‡Ù„ÙŠÙ† ÙˆÙ…Ø¯Ù‚Ù‚ÙŠÙ†ØŒ ÙˆØªÙ‚Ø¯Ù… Ø¬Ù„Ø³Ø§Øª Ø´Ø®ØµÙŠØ© ÙˆØ¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙÙŠ 20 Ù…ÙˆØ¶ÙˆØ¹Ù‹Ø§ Ø£Ø³Ø§Ø³ÙŠÙ‹Ø§ ØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©ØŒ Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠØ© ÙˆØ§Ù„Ù…Ù‡Ù†ÙŠØ©."
    elif prompt.lower() in ("Ø£ÙŠÙ† ÙŠÙ‚Ø¹ Ø£Ù„ØºÙˆØ±Ùˆ","Ø£ÙŠÙ† ÙŠÙ‚Ø¹ Ù…Ù‚Ø±ÙƒØŸ","Ø£ÙŠÙ† Ù…ÙˆÙ‚Ø¹ÙƒØŸ","Ø£ÙŠÙ† Ø´Ø±ÙƒØªÙƒ ØŸ","Ø£ÙŠÙ† ØªØ¬Ø±ÙŠ Ø§Ù„Ø¬Ù„Ø³Ø§ØªØŸ","Ù…Ø§ Ù‡ÙŠ Ø®Ø¯Ù…Ø§ØªÙƒØŸ"):
        response = "AlGooru Ù‡ÙŠ Ù…Ù†ØµØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØ±Ø¨Ø· Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù…Ø¹Ù„Ù…ÙŠÙ† Ù…Ø¤Ù‡Ù„ÙŠÙ† ÙˆÙ…Ø¯Ù‚Ù‚ÙŠÙ†ØŒ ÙˆØªÙ‚Ø¯Ù… Ø¬Ù„Ø³Ø§Øª Ø´Ø®ØµÙŠØ© ÙˆØ¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙÙŠ 20 Ù…ÙˆØ¶ÙˆØ¹Ù‹Ø§ Ø£Ø³Ø§Ø³ÙŠÙ‹Ø§ ØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©ØŒ Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠØ© ÙˆØ§Ù„Ù…Ù‡Ù†ÙŠØ©."
    elif prompt.lower() in ("ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ÙƒØŸ","ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹Ùƒ"):
        response = "AlGooru Ù‡ÙŠ Ù…Ù†ØµØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØ±Ø¨Ø· Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù…Ø¹Ù„Ù…ÙŠÙ† Ù…Ø¤Ù‡Ù„ÙŠÙ† ÙˆÙ…Ø¯Ù‚Ù‚ÙŠÙ†ØŒ ÙˆØªÙ‚Ø¯Ù… Ø¬Ù„Ø³Ø§Øª Ø´Ø®ØµÙŠØ© ÙˆØ¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙÙŠ 20 Ù…ÙˆØ¶ÙˆØ¹Ù‹Ø§ Ø£Ø³Ø§Ø³ÙŠÙ‹Ø§ ØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©ØŒ Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠØ© ÙˆØ§Ù„Ù…Ù‡Ù†ÙŠØ©."
    elif prompt.lower() in ("Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø­Ø¯ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø²Ù… Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù„ÙŠ Ø¨Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„ÙŠÙ‡Ø§ØŸ","Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø­Ø¯ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø²Ù… Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù„ÙŠ Ø¨Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„ÙŠÙ‡Ø§ØŸ"):
        response = "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø¨Ø§Ù‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯ØŒ ÙˆØ³ÙŠÙ‚ÙˆÙ… ÙØ±ÙŠÙ‚Ù†Ø§ Ø¨Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªÙ„Ø¨ÙŠØ© Ø·Ù„Ø¨Ùƒ."
    elif prompt.lower() in ("ÙƒÙ… ØªØªÙ‚Ø§Ø¶Ù‰ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¬Ù„Ø³Ø©ØŸ","ÙƒÙ… ØªØªÙ‚Ø§Ø¶Ù‰ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¬Ù„Ø³Ø©"):
        response = "ØªØªØ±Ø§ÙˆØ­ Ø£Ø³Ø¹Ø§Ø±Ù†Ø§ Ù„Ù„Ø³Ø§Ø¹Ø© Ù…Ù† 88 Ø¥Ù„Ù‰ 152 Ø±ÙŠØ§Ù„ Ø³Ø¹ÙˆØ¯ÙŠØŒ Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ù‚Ø© Ø§Ù„ØªÙŠ Ø§Ø®ØªØ±ØªÙ‡Ø§. Ø³ÙŠÙˆØµÙŠ Ø®Ø¨Ø±Ø§Ø¤Ù†Ø§ Ø¨Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„ØªÙŠ ØªÙ†Ø§Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ ÙˆØªÙØ¶ÙŠÙ„Ø§ØªÙƒ."

    else:
        try:
             response1 = model.generate_content([
                "You are an expert customer assistant from AlGooru Team. I'll give you question and context and you'll return the answer.Answer in 60 words in a paragraph. Do not give random answers. Always answer in arabic language ",
                f"Question: {prompt}",
                f"Context: {content}"
            ],safety_settings=safe)
             response = f"{response1.text}"
        except:
            response = "Ø¢Ø³Ù Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„ÙŠØ³ Ø°Ø§Øª ØµÙ„Ø©! Ù…Ù† ÙØ¶Ù„Ùƒ Ø­Ø§ÙˆÙ„ Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø±"
            # st.write("Sorry the question is not relevent! Please try asking another question")
    
         
        # flag = model.generate_content(["If "+prompt+" is related to anything like LGBTQ+, mention of homosexuality, politics, war news, crimes, etc. return '1' else return '0'"], safety_settings='HARM_CATEGORY_HATE_SPEECH')
        # flag = model.generate_content([prompt+"Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø±ØªØ¨Ø·Ù‹Ø§ Ø¨Ø£ÙŠ Ø´ÙŠØ¡ Ù…Ø«Ù„ LGBTQ+ØŒ Ø£Ùˆ Ø°ÙƒØ± Ø§Ù„Ù…Ø«Ù„ÙŠØ© Ø§Ù„Ø¬Ù†Ø³ÙŠØ©ØŒ Ø£Ùˆ Ø§Ù„Ø³ÙŠØ§Ø³Ø©ØŒ Ø£Ùˆ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø±Ø¨ØŒ Ø£Ùˆ Ø§Ù„Ø¬Ø±Ø§Ø¦Ù…ØŒ ÙˆÙ…Ø§ Ø¥Ù„Ù‰ Ø°Ù„Ùƒ. Ù‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ 1 ÙˆØ¥Ù„Ø§ Ù‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ 0"])
        # # st.write(flag.text)
        # if '1' in str(flag.text):
        #     response = "I am a parenting and educational assistance bot. I am unable to answer these questions. Please ask questions related to educational assistance."
        # elif '0' in str(flag.text):            
        # # context_truncated = textwrap.shorten(content, width=1000)
        #     response1 = model.generate_content([
        #         "You are an expert customer assistant from AlGooru Team. I'll give you question and context and you'll return the answer.Answer in 60 words in a paragraph. Do not give random answers. Always answer in arabic language ",
        #         f"Question: {prompt}",
        #         f"Context: {content}"
        #     ])
        #     response = f"{response1.text}"
        # else:
            # st.write(str(flag.text))
            # response = "I'm sorry, can you please try rephrasing your question?"

    # st.write(response)

    with st.chat_message("assistant"):
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
